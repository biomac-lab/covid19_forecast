{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.dates import date2num, num2date\n",
    "from matplotlib import dates as mdates\n",
    "from matplotlib import ticker\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "### ---- ###\n",
    "from functions.adjust_cases_functions import prepare_cases\n",
    "from global_config import config\n",
    "\n",
    "\n",
    "\n",
    "#dict_map = {'0-19': (0,19), '20-39': (20,39), '40-49': (40,49),\n",
    "#            '50-59': (50,59), '60-69': (60,69), '70-90+': (70,200) }\n",
    "\n",
    "\n",
    "dict_map = {'10-10': (0,19), '10-19': (10, 19), '20-39': (20,39), '40-49': (40,49),\n",
    "            '50-59': (50,59), '60-69': (60,69), '70-90+': (70,200) }\n",
    "\n",
    "NGroups  = len(dict_map)\n",
    "\n",
    "def age_group(val, dict_map):\n",
    "    for ag in dict_map:\n",
    "        if dict_map[ag][0] <= val <= dict_map[ag][1]:\n",
    "            return ag\n",
    "    return 'NaN'\n",
    "\n",
    "data_dir      = config.get_property('data_dir_covid')\n",
    "data_dir_mnps = config.get_property('data_dir_col')\n",
    "results_dir   = config.get_property('results_dir')\n",
    "\n",
    "location_folder = 'colombia'\n",
    "agglomeration_method = 'geometry'\n",
    "type_run = 'all'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaosdonkey06/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (14,22) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "983it [05:24,  2.88it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Agglomerated folder location\n",
    "agglomerated_folder = os.path.join(data_dir, 'data_stages', location_folder, 'agglomerated', agglomeration_method )\n",
    "\n",
    "raw_folder          = os.path.join(data_dir, 'data_stages', location_folder, 'raw' , 'cases')\n",
    "\n",
    "poly_agg_path  = os.path.join(data_dir_mnps, 'administrative_division_col_2018.csv' )\n",
    "poly_agg_df    = pd.read_csv(poly_agg_path, sep =',').set_index('poly_id')\n",
    "\n",
    "\n",
    "cases_df_all = pd.read_csv(os.path.join(agglomerated_folder, 'cases.csv'), parse_dates =['date_time']).set_index('poly_id')\n",
    "cases_df = cases_df_all.copy()\n",
    "\n",
    "#poly_id2location = cases_df.copy().reset_index().groupby(['poly_id', 'location']).sum().reset_index()[['poly_id', 'location']].set_index('poly_id')\n",
    "\n",
    "cases_raw_df = pd.read_csv(os.path.join(raw_folder, 'cases_raw.csv'), parse_dates =['Fecha de inicio de síntomas', 'Fecha de diagnóstico', 'Fecha de muerte'], dayfirst=True) #.set_index('poly_id')\n",
    "cases_raw_df['age_group'] = cases_raw_df['Edad'].apply(lambda x: age_group( x, dict_map) )\n",
    "cases_raw_df = cases_raw_df[['Código DIVIPOLA municipio', 'Nombre municipio', 'Nombre departamento',  'age_group', 'Sexo' ,'Fecha de inicio de síntomas', 'Fecha de diagnóstico', 'Fecha de muerte']]\n",
    "cases_raw_df = cases_raw_df.rename(columns={'Código DIVIPOLA municipio': 'poly_id'})\n",
    "\n",
    "#poly_id2location = cases_raw_df.copy().reset_index().groupby(['poly_id','Nombre municipio', 'Nombre departamento']).sum().reset_index().set_index('poly_id')\n",
    "#poly_id2location['location'] = poly_id2location.apply(lambda x: x['Nombre municipio'].lower()+'-'+x['Nombre departamento'].lower(), axis=1).reset_index()\n",
    "\n",
    "list_df_ages = []\n",
    "for age_g in dict_map.keys():\n",
    "    cases_agei = cases_raw_df[cases_raw_df.age_group==age_g].copy()\n",
    "    cases_agei['num_cases']    = 1\n",
    "    cases_agei['num_diseased'] = 1\n",
    "    cases_agei_num_cases  = cases_agei.copy().groupby(['Fecha de diagnóstico','poly_id']).sum().reset_index().rename(columns={'Fecha de diagnóstico': 'date_time'})[['date_time','poly_id','num_cases']]\n",
    "    cases_agei_num_deaths = cases_agei.copy()[['Fecha de muerte','poly_id','num_diseased']].dropna().groupby(['Fecha de muerte','poly_id']).sum().reset_index().rename(columns={'Fecha de muerte': 'date_time'})\n",
    "    new_df = pd.merge(cases_agei_num_cases, cases_agei_num_deaths,  how='outer').fillna(0)\n",
    "    new_df = new_df.groupby(['date_time','poly_id']).sum().reset_index().set_index('poly_id')\n",
    "    new_df['age_group'] = age_g\n",
    "    list_df_ages.append(new_df)\n",
    "\n",
    "cases_df_agg = cases_df.reset_index()[['poly_id','date_time', 'num_cases', 'num_diseased']]\n",
    "cases_df_agg['age_group'] = 'agg'\n",
    "list_df_ages.append(cases_df_agg.set_index('poly_id'))\n",
    "df_cases_ages = pd.concat(list_df_ages)\n",
    "\n",
    "poly_df  = pd.read_csv(os.path.join(agglomerated_folder, 'polygons.csv')).set_index('poly_id')\n",
    "\n",
    "## add time delta\n",
    "df_polygons = pd.read_csv( os.path.join( agglomerated_folder ,  \"polygons.csv\") )\n",
    "\n",
    "# Time delay between FIS and diagnosis date\n",
    "poly_df   = pd.read_csv( os.path.join( agglomerated_folder ,  \"polygons.csv\") ).set_index('poly_id')\n",
    "pop_df = poly_df.copy()[['attr_area', 'geometry', 'attr_population']]\n",
    "\n",
    "poly_df = poly_df.dropna(subset=['attr_time-delay_dist_mix', 'attr_time_death-delay_dist_mix'], axis='rows')\n",
    "\n",
    "poly_df[\"attr_time-delay_dist_mix\"] = poly_df[\"attr_time-delay_dist_mix\"].fillna(\"\")\n",
    "poly_df = poly_df.dropna(subset=['attr_time-delay_dist_mix'], axis=0)\n",
    "poly_df[\"attr_time_diag_delay\"] = poly_df.apply(lambda x: np.fromstring(x[\"attr_time-delay_dist_mix\"], sep=\"|\"), axis=1)\n",
    "poly_df = poly_df[poly_df['attr_time_diag_delay'].map(lambda x: len(x)) > 0]\n",
    "poly_df = poly_df[poly_df['attr_time_diag_delay'].map(lambda x: ~np.isnan(list(x)[0] ))]\n",
    "\n",
    "\n",
    "poly_df[\"attr_time_death-delay_dist_mix\"] = poly_df[\"attr_time_death-delay_dist_mix\"].fillna(\"\")\n",
    "poly_df[\"attr_time_death_delay\"]          = poly_df.apply(lambda x: np.fromstring(x[\"attr_time_death-delay_dist_mix\"], sep=\"|\"), axis=1)\n",
    "poly_df = poly_df.dropna(subset=['attr_time_death-delay_dist_mix'], axis=0)\n",
    "poly_df[\"attr_time_death_delay\"] = poly_df.apply(lambda x: np.fromstring(x[\"attr_time_death-delay_dist_mix\"], sep=\"|\"), axis=1)\n",
    "poly_df = poly_df[poly_df['attr_time_death_delay'].map(lambda x: len(x)) > 0]\n",
    "poly_df = poly_df[poly_df['attr_time_death_delay'].map(lambda x: ~np.isnan(list(x)[0] ))]\n",
    "\n",
    "agg_p_delay_diag  = pd.DataFrame(list(poly_df['attr_time_diag_delay'])).mean().to_numpy()\n",
    "agg_p_delay_diag[0] = 0\n",
    "\n",
    "agg_p_delay_death = pd.DataFrame(list(poly_df['attr_time_death_delay'])).mean().to_numpy()\n",
    "agg_p_delay_death[0] = 0\n",
    "\n",
    "def crosscorr(cases, deaths, lag=0):\n",
    "    \"\"\" Lag-N cross correlation. \n",
    "    Parameters\n",
    "    ----------\n",
    "    lag : int, default 0\n",
    "    datax, datay : pandas.Series objects of equal length\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    crosscorr : float\n",
    "    \"\"\"\n",
    "    return deaths.corr(cases.shift(lag))\n",
    "\n",
    "\n",
    "def compute_correlation(cases, deaths, lags = list(range(41)), start_day='01-04-2020', final_day=None):\n",
    "\n",
    "    if not start_day:\n",
    "        start_day = min(cases.index.values[0], deaths.index.values[0])\n",
    "    if not final_day:\n",
    "        final_day = min(cases.index.values[-1], deaths.index.values[-1])\n",
    "\n",
    "    min_date = pd.to_datetime(start_day, dayfirst=True)\n",
    "    max_date = pd.to_datetime(final_day, dayfirst=True)\n",
    "\n",
    "    cases = cases.loc[start_day:max_date]\n",
    "    deaths = deaths.loc[start_day:max_date]\n",
    "\n",
    "    corr_df = pd.DataFrame(columns = ['lag', 'value'])\n",
    "    corr_df['lag'] = lags\n",
    "    corr_df = corr_df.set_index('lag')\n",
    "\n",
    "    for idx, lag in enumerate(lags):\n",
    "        corr_df.loc[lag]['value'] = crosscorr(cases, deaths, lag=lag)\n",
    "\n",
    "    return corr_df\n",
    "\n",
    "\n",
    "def cfr(cases, deaths, lag, start_day='01-04-2020', final_day=None):\n",
    "\n",
    "    if not start_day:\n",
    "        start_day = min(cases.index.values[0], deaths.index.values[0])\n",
    "    if not final_day:\n",
    "        final_day = min(cases.index.values[-1], deaths.index.values[-1])\n",
    "\n",
    "    #start_day = '01-04-2020'\n",
    "    #final_day = '31-10-2020'\n",
    "\n",
    "    min_date = pd.to_datetime(start_day, dayfirst=True)\n",
    "    max_date = pd.to_datetime(final_day, dayfirst=True)\n",
    "\n",
    "    min_init = min(cases.index.values[0], deaths.index.values[0])\n",
    "    min_date = min(min_date, min_init)\n",
    "\n",
    "    max_init = min(cases.index.values[-1], deaths.index.values[-1])\n",
    "    max_date = min(max_date, max_init)\n",
    "\n",
    "\n",
    "    cases = cases.loc[min_date:max_date]\n",
    "    deaths = deaths.loc[min_date:max_date]\n",
    "\n",
    "    cfr = pd.DataFrame(columns = ['date_time', 'value'])\n",
    "\n",
    "    #cfr['date_time'] = pd.date_range(start=min_date, end=max_date, freq='D')\n",
    "    #cfr['value']     = deaths.shift(lag).values / cases.values\n",
    "\n",
    "    return deaths.shift(lag).values / cases.values\n",
    "\n",
    "cases_df['state']    = cases_df.apply(lambda x: x['location'].split('-')[-1], axis=1)\n",
    "state2id = {}\n",
    "for state_id in cases_df['state'].unique():\n",
    "    poly_id = str(cases_df.reset_index().set_index(\"state\").loc[state_id]['poly_id'].iloc[0])\n",
    "    if len(poly_id)==4: #==state_id\")['poly_id'].iloc[0])==4:\n",
    "        state2id[state_id] = '0'+poly_id[:1]\n",
    "    else:\n",
    "        state2id[state_id] = poly_id[:2]\n",
    "\n",
    "def get_location_state(poly_id, cases_df_all):\n",
    "    try:\n",
    "        location = cases_df_all.loc[poly_id]['location'].iloc[0]\n",
    "    except:\n",
    "        return 'None'\n",
    "\n",
    "    return (location.split('-')[0], location.split('-')[1])\n",
    "\n",
    "from tqdm import tqdm\n",
    "poly_info = {}\n",
    "for idx, poly_id in tqdm(enumerate(cases_df.reset_index()['poly_id'].unique())):\n",
    "\n",
    "    # If polygon not in polygons use aggregated p_delay\n",
    "    if poly_id in poly_df.index.values:\n",
    "        p_delay_diag = poly_df.loc[poly_id][\"attr_time_diag_delay\"]\n",
    "    else:\n",
    "        p_delay_diag = agg_p_delay_diag\n",
    "\n",
    "    if poly_id in poly_df.index.values:\n",
    "        p_delay_death = poly_df.loc[poly_id][\"attr_time_death_delay\"]\n",
    "    else:\n",
    "        p_delay_death = agg_p_delay_death\n",
    "\n",
    "    try:\n",
    "        list_cases_df = []\n",
    "        for age_group in df_cases_ages.age_group.unique():\n",
    "            cases_df = df_cases_ages[df_cases_ages.age_group==age_group]\n",
    "            cases  = cases_df.loc[poly_id][['date_time','num_cases']].set_index('date_time').resample('D').sum().fillna(0)[['num_cases']]\n",
    "            cases  = prepare_cases(cases, col='num_cases', cutoff=0)\n",
    "            cases['age_group'] = age_group\n",
    "            list_cases_df.append(cases)\n",
    "        cases = pd.concat(list_cases_df)\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    list_deaths_df = []\n",
    "    for age_group in df_cases_ages.age_group.unique():\n",
    "        deaths_df = df_cases_ages[df_cases_ages.age_group==age_group]\n",
    "        deaths  = deaths_df.loc[poly_id][['date_time','num_diseased']].set_index('date_time').resample('D').sum().fillna(0)[['num_diseased']]\n",
    "        deaths['age_group'] = age_group\n",
    "        list_deaths_df.append(deaths)\n",
    "    deaths = pd.concat(list_deaths_df)\n",
    "\n",
    "\n",
    "\n",
    "    if deaths[deaths.age_group=='agg']['num_diseased'].sum() <= 100:\n",
    "        continue\n",
    "    start_date = deaths[deaths.age_group=='agg'].index.values[np.where(deaths[deaths.age_group=='agg']['num_diseased'].cumsum()>=1)[0][0]] + pd.Timedelta(days=8)\n",
    "    #df_corr_poly_id = compute_correlation(cases_onset['num_cases'], deaths['num_diseased'], lags = list(range(41)), start_day=start_date, final_day='31-10-2020')\n",
    "\n",
    "    poly_info[poly_id] = {\n",
    "                    'poly_id'         : poly_id,\n",
    "                    'poly_name'       : get_location_state(poly_id, cases_df_all)[0],\n",
    "                    'state'           : get_location_state(poly_id, cases_df_all)[1],\n",
    "                    'population'      : pop_df.loc[poly_id]['attr_population'],\n",
    "                    'area'            : pop_df.loc[poly_id]['attr_area'],\n",
    "                    'delay_diag'      : p_delay_diag,\n",
    "                    'delay_death'     : p_delay_death,\n",
    "                    'geometry'        : pop_df.loc[poly_id]['geometry']\n",
    "                    }\n",
    "    # TODO: add                key 'corr_lag'        : df_corr_poly_id\n",
    "    path_to_save = os.path.join( results_dir, 'colombia', 'cfr')\n",
    "\n",
    "    for age_group in deaths.age_group.unique():\n",
    "        cases_ag = cases[cases.age_group==age_group][['num_cases', 'smoothed_num_cases']]\n",
    "    \n",
    "        poly_info[poly_id]['cases_diag_{}'.format(age_group)]  = cases_ag\n",
    "        poly_info[poly_id]['cases_onset_{}'.format(age_group)] = confirmed_to_onset(cases_ag['smoothed_num_cases'], p_delay_diag, 'num_cases')\n",
    "        poly_info[poly_id]['deaths_{}'.format(age_group)]      = deaths[deaths.age_group==age_group][['num_diseased']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
