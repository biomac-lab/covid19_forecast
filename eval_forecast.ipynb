{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python382jvsc74a57bd0b01649901317fc5b81743eb8eebb38460d713d5e052e75bd5eb11f129314e786",
   "display_name": "Python 3.8.2 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "**** Running evaluation for hist. forecast for bogota\n",
      "**** **** Last day uploaded 2021-May-08\n",
      "**** **** *** Droping last 2wk\n"
     ]
    }
   ],
   "source": [
    "from functions.adjust_cases_functions import prepare_cases\n",
    "from functions.general_utils import  get_bool\n",
    "from models.seird_model import SEIRD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from global_config import config\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "poly_run  = 11001   #int(sys.argv[1])\n",
    "name_dir  = 'bogota' #str(sys.argv[2])\n",
    "drop_last_weeks = True #get_bool(sys.argv[3])\n",
    "\n",
    "print(\"**** Running evaluation for hist. forecast for {}\".format(name_dir))\n",
    "\n",
    "data_dir            = config.get_property('data_dir_covid')\n",
    "geo_dir             = config.get_property('geo_dir')\n",
    "data_dir_mnps       = config.get_property('data_dir_col')\n",
    "results_dir         = config.get_property('results_dir')\n",
    "agglomerated_folder = os.path.join(data_dir, 'data_stages', 'colombia', 'agglomerated', 'geometry' )\n",
    "\n",
    "polygons = pd.read_csv(os.path.join(agglomerated_folder, 'polygons.csv')).set_index('poly_id')\n",
    "polygons = polygons.loc[poly_run]\n",
    "\n",
    "data  =  pd.read_csv(os.path.join(agglomerated_folder, 'cases.csv'), parse_dates=['date_time'],\n",
    "                    dayfirst=True).set_index('poly_id').loc[poly_run].set_index('date_time')\n",
    "\n",
    "data  = data.resample('D').sum().fillna(0)[['num_cases','num_diseased']]\n",
    "data  = prepare_cases(data, col='num_cases', cutoff=0)    # .rename({'smoothed_num_cases':'num_cases'})\n",
    "data  = prepare_cases(data, col='num_diseased', cutoff=0) # .rename({'smoothed_num_cases':'num_cases'})\n",
    "data  = data.rename(columns={'smoothed_num_cases': 'confirmed', 'smoothed_num_diseased':'death'})[['confirmed', 'death']]\n",
    "\n",
    "print(\"**** **** Last day uploaded {}\".format(pd.to_datetime(data.index.values[-1]).strftime('%Y-%b-%d')))\n",
    "\n",
    "if drop_last_weeks:\n",
    "    print(\"**** **** *** Droping last 2wk\")\n",
    "    data = data.iloc[:-14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_place = os.path.join(results_dir, 'weekly_forecast' , name_dir) #pd.to_datetime(data.index.values[-1]).strftime('%Y-%m-%d'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   date_frcst                                      path_to_frcst\n",
       "11 2021-01-19  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "20 2021-01-23  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "10 2021-01-27  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "8  2021-01-29  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "14 2021-01-30  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "9  2021-02-07  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "0  2021-02-13  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "1  2021-02-14  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "12 2021-02-20  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "13 2021-02-27  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "19 2021-03-03  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "4  2021-03-14  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "16 2021-03-17  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "15 2021-03-21  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "17 2021-03-27  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "3  2021-04-03  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "6  2021-04-10  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "7  2021-04-17  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "5  2021-04-18  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "18 2021-04-24  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_frcst</th>\n      <th>path_to_frcst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>2021-01-19</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2021-01-23</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2021-01-27</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2021-01-29</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2021-01-30</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2021-02-07</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2021-02-13</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-02-14</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2021-02-20</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2021-02-27</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2021-03-03</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-03-14</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2021-03-17</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2021-03-21</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2021-03-27</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-04-03</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2021-04-10</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2021-04-17</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2021-04-18</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2021-04-24</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "dates_df = pd.DataFrame(data=os.listdir(path_to_place), columns=['date_frcst'])\n",
    "dates_df = dates_df[dates_df['date_frcst'] != '.DS_Store']\n",
    "dates_df[\"date_frcst\"] = pd.to_datetime(dates_df[\"date_frcst\"])\n",
    "dates_df = dates_df.sort_values(by='date_frcst')\n",
    "dates_df[\"path_to_frcst\"] = dates_df[\"date_frcst\"].map(lambda x: os.path.join(path_to_place, x.strftime('%Y-%m-%d') ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_frcst_df = pd.read_csv(os.path.join(dates_df[\"path_to_frcst\"].iloc[1], 'deaths_df.csv' ), parse_dates=[\"date\"])\n",
    "cases_frcst_df  = pd.read_csv(os.path.join(dates_df[\"path_to_frcst\"].iloc[1], 'cases_df.csv' ), parse_dates=[\"date\"])\n",
    "\n",
    "deaths_frcst_df = deaths_frcst_df[deaths_frcst_df[\"type\"]=='forecast']\n",
    "cases_frcst_df = cases_frcst_df[cases_frcst_df[\"type\"]=='forecast']\n",
    "\n",
    "model = SEIRD(\n",
    "    confirmed = data['confirmed'].cumsum(),\n",
    "    death     = data['death'].cumsum(),\n",
    "    T         = len(data),\n",
    "    N         = int(polygons[\"attr_population\"]),\n",
    "    samples   = mcmc_samples\n",
    "    )\n",
    "    \n",
    "def load_samples(filename):\n",
    "\n",
    "    x = np.load(filename, allow_pickle=True)\n",
    "\n",
    "    mcmc_samples = x['mcmc_samples'].item()\n",
    "    post_pred_samples = x['post_pred_samples'].item()\n",
    "    forecast_samples = x['forecast_samples'].item()\n",
    "\n",
    "    return mcmc_samples, post_pred_samples, forecast_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.contrib.forecast import eval_crps, eval_mae, eval_rmse\n",
    "\n",
    "import torch\n",
    "\n",
    "mcmc_samples, post_pred_samples, forecast_samples = load_samples(os.path.join(dates_df[\"path_to_frcst\"].iloc[1], 'samples.npz'  ))\n",
    "\n",
    "forecast_samples['mean_dz0'] = forecast_samples[\"dz0\"]\n",
    "forecast_samples['mean_dy0'] = forecast_samples[\"dy0\"]\n",
    "deaths_fitted = model.combine_samples(forecast_samples, f='mean_dz', use_future=True)\n",
    "cases_fitted  = model.combine_samples(forecast_samples, f='mean_dy', use_future=True)\n",
    "dates_frcst = deaths_frcst_df[\"date\"]\n",
    "deaths_fore = deaths_fitted[:, deaths_frcst_df.index.values]\n",
    "cases_fore  = cases_fitted[:, cases_frcst_df.index.values]\n",
    "data_eval = data.loc[dates_frcst]\n",
    "\n",
    "death_samples = torch.tensor(np.array(deaths_fore)); deaths_obs = torch.tensor(list(data_eval[\"death\"].values))\n",
    "cases_samples = torch.tensor(np.array(cases_fore));  cases_obs  = torch.tensor(list(data_eval[\"confirmed\"].values))\n",
    "\n",
    "\n",
    "def compute_evals(samples_d, samples_c, obs_d, obs_c):\n",
    "    \n",
    "    weekdict = {'1w':6, '2w': 13, '3w': 20, '4w': 26}\n",
    "    for kw in weekdict.keys()\n",
    "        w = weekdict[kw]\n",
    "\n",
    "        death_crps = eval_crps( samples_d[:w], obs_d[:w] )\n",
    "        cases_crps = eval_crps( samples_c[:w], obs_c[:w] )\n",
    "\n",
    "        death_mae = eval_mae( samples_d[:W], obs_d[:w] )\n",
    "        cases_mae = eval_mae( samples_c[:W], obs_c[:w] )\n",
    "\n",
    "        death_rmse = eval_rmse( samples_d[:w], obs_d[:w] )\n",
    "        cases_rmse = eval_rmse( samples_c[:w], obs_c[:w] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "confirmed    981.0\n",
       "death         17.0\n",
       "Name: 2021-02-19 00:00:00, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "data_eval.iloc[27-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}