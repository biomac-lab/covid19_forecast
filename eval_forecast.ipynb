{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python382jvsc74a57bd0b01649901317fc5b81743eb8eebb38460d713d5e052e75bd5eb11f129314e786",
   "display_name": "Python 3.8.2 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "**** Running evaluation for hist. forecast for bogota\n",
      "**** **** Last day uploaded 2021-May-08\n",
      "**** **** *** Droping last 2wk\n"
     ]
    }
   ],
   "source": [
    "from functions.adjust_cases_functions import prepare_cases\n",
    "from functions.general_utils import  get_bool\n",
    "from models.seird_model import SEIRD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from global_config import config\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "poly_run  = 11001   #int(sys.argv[1])\n",
    "name_dir  = 'bogota' #str(sys.argv[2])\n",
    "drop_last_weeks = True #get_bool(sys.argv[3])\n",
    "\n",
    "print(\"**** Running evaluation for hist. forecast for {}\".format(name_dir))\n",
    "\n",
    "data_dir            = config.get_property('data_dir_covid')\n",
    "geo_dir             = config.get_property('geo_dir')\n",
    "data_dir_mnps       = config.get_property('data_dir_col')\n",
    "results_dir         = config.get_property('results_dir')\n",
    "agglomerated_folder = os.path.join(data_dir, 'data_stages', 'colombia', 'agglomerated', 'geometry' )\n",
    "\n",
    "polygons = pd.read_csv(os.path.join(agglomerated_folder, 'polygons.csv')).set_index('poly_id')\n",
    "polygons = polygons.loc[poly_run]\n",
    "\n",
    "data  =  pd.read_csv(os.path.join(agglomerated_folder, 'cases.csv'), parse_dates=['date_time'],\n",
    "                    dayfirst=True).set_index('poly_id').loc[poly_run].set_index('date_time')\n",
    "\n",
    "data  = data.resample('D').sum().fillna(0)[['num_cases','num_diseased']]\n",
    "data  = prepare_cases(data, col='num_cases', cutoff=0)    # .rename({'smoothed_num_cases':'num_cases'})\n",
    "data  = prepare_cases(data, col='num_diseased', cutoff=0) # .rename({'smoothed_num_cases':'num_cases'})\n",
    "data  = data.rename(columns={'smoothed_num_cases': 'confirmed', 'smoothed_num_diseased':'death'})[['confirmed', 'death']]\n",
    "\n",
    "print(\"**** **** Last day uploaded {}\".format(pd.to_datetime(data.index.values[-1]).strftime('%Y-%b-%d')))\n",
    "\n",
    "if drop_last_weeks:\n",
    "    print(\"**** **** *** Droping last 2wk\")\n",
    "    data = data.iloc[:-14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_place = os.path.join(results_dir, 'weekly_forecast' , name_dir) #pd.to_datetime(data.index.values[-1]).strftime('%Y-%m-%d'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   date_frcst                                      path_to_frcst\n",
       "11 2021-01-19  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "20 2021-01-23  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "10 2021-01-27  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "8  2021-01-29  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "14 2021-01-30  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "9  2021-02-07  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "0  2021-02-13  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "1  2021-02-14  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "12 2021-02-20  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "13 2021-02-27  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "19 2021-03-03  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "4  2021-03-14  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "16 2021-03-17  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "15 2021-03-21  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "17 2021-03-27  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "3  2021-04-03  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "6  2021-04-10  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "7  2021-04-17  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "5  2021-04-18  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...\n",
       "18 2021-04-24  /Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_frcst</th>\n      <th>path_to_frcst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>2021-01-19</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2021-01-23</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2021-01-27</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2021-01-29</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2021-01-30</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2021-02-07</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2021-02-13</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-02-14</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2021-02-20</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2021-02-27</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2021-03-03</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-03-14</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2021-03-17</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2021-03-21</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2021-03-27</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-04-03</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2021-04-10</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2021-04-17</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2021-04-18</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2021-04-24</td>\n      <td>/Users/chaosdonkey06/Dropbox/BIOMAC/EAKF_Forec...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "dates_df = pd.DataFrame(data=os.listdir(path_to_place), columns=['date_frcst'])\n",
    "dates_df = dates_df[dates_df['date_frcst'] != '.DS_Store']\n",
    "dates_df[\"date_frcst\"] = pd.to_datetime(dates_df[\"date_frcst\"])\n",
    "dates_df = dates_df.sort_values(by='date_frcst')\n",
    "dates_df[\"path_to_frcst\"] = dates_df[\"date_frcst\"].map(lambda x: os.path.join(path_to_place, x.strftime('%Y-%m-%d') ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_frcst_df = pd.read_csv(os.path.join(dates_df[\"path_to_frcst\"].iloc[1], 'deaths_df.csv' ), parse_dates=[\"date\"])\n",
    "cases_frcst_df  = pd.read_csv(os.path.join(dates_df[\"path_to_frcst\"].iloc[1], 'cases_df.csv' ), parse_dates=[\"date\"])\n",
    "\n",
    "deaths_frcst_df = deaths_frcst_df[deaths_frcst_df[\"type\"]=='forecast']\n",
    "cases_frcst_df = cases_frcst_df[cases_frcst_df[\"type\"]=='forecast']\n",
    "\n",
    "model = SEIRD(\n",
    "    confirmed = data['confirmed'].cumsum(),\n",
    "    death     = data['death'].cumsum(),\n",
    "    T         = len(data),\n",
    "    N         = int(polygons[\"attr_population\"]),\n",
    "    samples   = mcmc_samples\n",
    "    )\n",
    "    \n",
    "def load_samples(filename):\n",
    "\n",
    "    x = np.load(filename, allow_pickle=True)\n",
    "\n",
    "    mcmc_samples = x['mcmc_samples'].item()\n",
    "    post_pred_samples = x['post_pred_samples'].item()\n",
    "    forecast_samples = x['forecast_samples'].item()\n",
    "\n",
    "    return mcmc_samples, post_pred_samples, forecast_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.contrib.forecast import eval_crps, eval_mae, eval_rmse\n",
    "\n",
    "import torch\n",
    "\n",
    "mcmc_samples, post_pred_samples, forecast_samples = load_samples(os.path.join(dates_df[\"path_to_frcst\"].iloc[1], 'samples.npz'  ))\n",
    "\n",
    "forecast_samples['mean_dz0'] = forecast_samples[\"dz0\"]\n",
    "forecast_samples['mean_dy0'] = forecast_samples[\"dy0\"]\n",
    "deaths_fitted = model.combine_samples(forecast_samples, f='mean_dz', use_future=True)\n",
    "cases_fitted  = model.combine_samples(forecast_samples, f='mean_dy', use_future=True)\n",
    "dates_frcst = deaths_frcst_df[\"date\"]\n",
    "deaths_fore = deaths_fitted[:, deaths_frcst_df.index.values]\n",
    "cases_fore  = cases_fitted[:, cases_frcst_df.index.values]\n",
    "data_eval = data.loc[dates_frcst]\n",
    "\n",
    "death_samples = torch.tensor(np.array(deaths_fore)); deaths_obs = torch.tensor(list(data_eval[\"death\"].values))\n",
    "cases_samples = torch.tensor(np.array(cases_fore));  cases_obs  = torch.tensor(list(data_eval[\"confirmed\"].values))\n",
    "\n",
    "\n",
    "def compute_evals(samples_d, samples_c, obs_d, obs_c):\n",
    "    \n",
    "    weekdict = {'1w':6, '2w': 13, '3w': 20, '4w': 26}\n",
    "\n",
    "    df_response_cases = pd.DataFrame(index=list(weekdict.keys()), columns=['crps', 'mae', 'rmse'])\n",
    "    df_response_deaths = pd.DataFrame(index=list(weekdict.keys()), columns=['crps', 'mae', 'rmse'])\n",
    "\n",
    "    for kw in weekdict.keys():\n",
    "        w = weekdict[kw]\n",
    "\n",
    "        df_response_deaths['crps'].loc[kw] = eval_crps( samples_d[:,:w], obs_d[:w] )\n",
    "        df_response_cases['crps'].loc[kw] = eval_crps( samples_c[:,:w], obs_c[:w] )\n",
    "    \n",
    "\n",
    "        df_response_deaths['mae'].loc[kw] = eval_mae( samples_d[:,:w], obs_d[:w] )\n",
    "        df_response_cases['mae'].loc[kw] = eval_mae( samples_c[:,:w], obs_c[:w] )\n",
    "\n",
    "        df_response_deaths['rmse'].loc[kw] = eval_rmse( samples_d[:,:w], obs_d[:w] )\n",
    "        df_response_cases['rmse'].loc[kw] = eval_rmse( samples_c[:,:w], obs_c[:w] )\n",
    "\n",
    "    df_response_cases[\"type\"] = 'cases'\n",
    "    df_response_deaths[\"type\"] = 'deaths'\n",
    "\n",
    "    return pd.concat([df_response_cases, df_response_deaths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          crps         mae         rmse    type\n",
       "1w  391.087166  319.051921   629.760226   cases\n",
       "2w  599.256637  599.917912  2102.218102   cases\n",
       "3w   804.47481  787.078955  3717.039766   cases\n",
       "4w  964.251628  841.286311  5359.268811   cases\n",
       "1w    6.417973    8.810402    13.571386  deaths\n",
       "2w   12.402773   17.202606    28.156882  deaths\n",
       "3w   14.848721   19.967548    43.537486  deaths\n",
       "4w   16.880891   21.290828    62.677093  deaths"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>crps</th>\n      <th>mae</th>\n      <th>rmse</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1w</th>\n      <td>391.087166</td>\n      <td>319.051921</td>\n      <td>629.760226</td>\n      <td>cases</td>\n    </tr>\n    <tr>\n      <th>2w</th>\n      <td>599.256637</td>\n      <td>599.917912</td>\n      <td>2102.218102</td>\n      <td>cases</td>\n    </tr>\n    <tr>\n      <th>3w</th>\n      <td>804.47481</td>\n      <td>787.078955</td>\n      <td>3717.039766</td>\n      <td>cases</td>\n    </tr>\n    <tr>\n      <th>4w</th>\n      <td>964.251628</td>\n      <td>841.286311</td>\n      <td>5359.268811</td>\n      <td>cases</td>\n    </tr>\n    <tr>\n      <th>1w</th>\n      <td>6.417973</td>\n      <td>8.810402</td>\n      <td>13.571386</td>\n      <td>deaths</td>\n    </tr>\n    <tr>\n      <th>2w</th>\n      <td>12.402773</td>\n      <td>17.202606</td>\n      <td>28.156882</td>\n      <td>deaths</td>\n    </tr>\n    <tr>\n      <th>3w</th>\n      <td>14.848721</td>\n      <td>19.967548</td>\n      <td>43.537486</td>\n      <td>deaths</td>\n    </tr>\n    <tr>\n      <th>4w</th>\n      <td>16.880891</td>\n      <td>21.290828</td>\n      <td>62.677093</td>\n      <td>deaths</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "source": [
    "df_stats = compute_evals(death_samples, cases_samples, deaths_obs, cases_obs)\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}